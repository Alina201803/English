

##11. web scraping

**源代码**

```python
import webbrowser
webbrowser.open('http://inventwithpython.com')
mapit 870 Valencia St, San Francisco, CA 94110

#!python 3
# mapIt.py - launches a map in the browser using an address from the 
# command line or clipboard.

import webbrowser, sys
if len(sys.argv) > 1:
    #Get address from command line.
    address = ' '.join(sys.argv[1:])
else:
    #Get address from clipboard.
    address = pyperclip.paste()

webbrowser.open('http://www.google.com/maps/place' + address)
```

**今日所学**

project：maplt.py with the webbrowser module

step1:figure out the URL

step2:handle the command line arguments

step3:handle the clipboard content and launch the browser



2018-09-02

**源代码**

```python
In [1]: import requests

In [2]: res = requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt
   ...: ')

In [3]:

In [3]: type(res)
Out[3]: requests.models.Response

In [4]: res.status_code == requests.codes.ok
Out[4]: True

In [5]: len(res.text)
Out[5]: 178981

In [6]: print(res.text[:250])
The Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare

This eBook is for the use of anyone anywhere at no cost and with
almost no restrictions whatsoever.  You may copy it, give it away or
re-use it under the terms of the Proje

In [7]: res = requests.get('http://inventwithpython.com/page_that_does_not_exis
   ...: t')

In [8]: res.raise_for_status()
---------------------------------------------------------------------------
HTTPError                                 Traceback (most recent call last)
<ipython-input-8-6ec835a6a98f> in <module>()
----> 1 res.raise_for_status()

D:\Anaconda\lib\site-packages\requests\models.py in raise_for_status(self)
    860
    861         if http_error_msg:
--> 862             raise HTTPError(http_error_msg, response=self)
    863
    864     def close(self):

HTTPError: 404 Client Error: Not Found for url: http://inventwithpython.com/page
_that_does_not_exist

In [9]: quit()

import requests
res = requests.get('http://inventwithpython.com/page_that_does_not_exist')
try:
    res.raise_for_status()
except Exception as exc:
    print('There was a problem: %s' %(exc))
    
```

**今日所学**

downloading files from the web with the requests ,module

downloading a web page with the requests.get() function

checking for errors



2018-09-03

**源代码**

```python
import requests
res = requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt')
res.raise_for_status()
playFile = open('RomeoAndJuliet.txt','wb')
for chunk in res.iter_content(100000):
    playFile.write(chunk)
playFile.close()
```

**今日所学**

saving downloaded files to the hard drive

 

2018-09-09

**源代码**

```python
<strong>hello</strong> world!
Al's free <a href="http:inventwithpython.com">Python books</a>

import requests, bs4
res = requests.get('http://nostarch.com')
res.raise_for_status()
noStarchSoup = bs4.Beau
Out[17]: list

In [18]:  type(elems[0])
    ...:
Out[18]: bs4.element.Tag

In [19]: elems[0].getText()
Out[19]: 'Al Sweigart'

In [20]: str(elems[0])
Out[20]: '<span id="author">Al Sweigart</span>'

In [21]: elems[0].attrs
Out[21]: {'id': 'author'}



In [29]: import bs4
In [31]: soup = bs4.BeautifulSoup(open('example.html'), 'lxml')

In [32]: spanElem = soup.select('span')[0]

In [33]: str(spanElem)
Out[33]: '<span id="author">Al Sweigart</span>'

In [34]: spanElem.get('id')
Out[34]: 'author'

In [35]: spanElem.get('some_nonexistent_addr') == None
Out[35]: True

In [36]: spanElem.attrs
Out[36]: {'id': 'author'}
    
#! python3
# lucky.py - Opens several Google search retifulSoup(res.text,  "lxml")
type(noStarchSoup)

In [1]: import bs4

In [2]: exampleFile = open('example.html')

In [3]: exampleSoup = bs4.BeautifulSoup(exampleFile, 'lxml')

In [4]: type(exampleSoup)
Out[4]: bs4.BeautifulSoup

In [17]:  import bs4
    ...:  exampleFile = open('example.html')
    ...:  exampleSoup = bs4.BeautifulSoup(exampleFile.read(), 'lxml')
    ...: elems = exampleSoup.select('#author')
    ...: type(elems)
    ...:sults.

import requests, sys, webbrowser, bs4

print('Googling...') #display text while downlosding the Google page
res = requests.get('http://google.com/serach?q=' + ' '.join(sys.argv[1:]))
res.raise_for_status()

# Retrieve top search result links.
soup = bs4.BeautifulSoup(res.text)

# Open a browser tab for each result.
linkElems = soup.select('.r a')
numOpen = min(5, len(linkElems))
for i in range(numOpen):
    webbrower.open('http://google.com' + linkElems[i].get('href'))
#-*-coding:utf-8-*-
#! python3
# downloadXkcd.py - Downloads every single XKCD cominc.
 
 
import requests,os,bs4
 
url = 'http://xkcd.com'               # starting url
os.makedirs('xkcd',exist_ok=True)      # store comics in ./xkcd
while not url.endswith('#'):
    # Download the page
    print('Downloading page %s...'% url)
    res = requests.get(url)
    res.raise_for_status()
    soup = bs4.BeautifulSoup(res.text,"html.parser")
    # Find the URL of the comic image.
    comicElem = soup.select('#comic img')
    if comicElem == []:
        print('Could not find comic image.')
    else:
        comicUrl = 'http:' + comicElem[0].get('src')
        # Download the image.
        print('Downloading image %s...'% (comicUrl))
        res = requests.get(comicUrl)
        res.raise_for_status()
        # Save the image to ./xkcd.
        imageFile = open(os.path.join('xkcd',os.path.basename(comicUrl)),'wb')
        for chunk in res.iter_content(100000):
            imageFile.write(chunk)
        imageFile.close()
     # Get the Prev button's url.
    prevLink = soup.select('a[rel="prev"]')[0]
    url = 'http://xkcd.com' + prevLink.get('href')
 
print('Done.')
```

**错题集**

```python
书上关于Project :downloading all xkcd comics 的代码会报错
Downloading page http://xkcd.com...
Downloading image //imgs.xkcd.com/comics/boathouses_and_houseboats.png...
Traceback (most recent call last):
  File "2018-09-09-1.py", line 25, in <module>
    res = requests.get(comicUrl)
  File "D:\Anaconda\lib\site-packages\requests\api.py", line 70, in get
    return request('get', url, params=params, **kwargs)
  File "D:\Anaconda\lib\site-packages\requests\api.py", line 56, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\Anaconda\lib\site-packages\requests\sessions.py", line 461, in reques                                                                                                                t
    prep = self.prepare_request(req)
  File "D:\Anaconda\lib\site-packages\requests\sessions.py", line 394, in prepar                                                                                                                e_request
    hooks=merge_hooks(request.hooks, self.hooks),
  File "D:\Anaconda\lib\site-packages\requests\models.py", line 294, in prepare
    self.prepare_url(url, params)
  File "D:\Anaconda\lib\site-packages\requests\models.py", line 354, in prepare_                                                                                                                url
    raise MissingSchema(error)
requests.exceptions.MissingSchema: Invalid URL '//imgs.xkcd.com/comics/boathouse                                                                                                                s_and_houseboats.png': No schema supplied. Perhaps you meant http:////imgs.xkcd.                                                                                                                com/comics/boathouses_and_houseboats.png?
、
soup = bs4.BeautifulSoup(res.text,"html.parser")
加上"html.patser"后 问题解决 
下载的图片实在太多了，手动停掉，感觉到了电脑做事的方便。

html.parser — Simple HTML and XHTML parser 
https://docs.python.org/3/library/html.parser.html

```

**今日所学**

HTML

resourses for learning HTML

viewing the source html of a web page

opening your broeser's developer tools

using the developer tools to find html elements

parsing html with beautifulsoup module

project "i'm feeling lucky " google search

project downloading all xkcd comics



2018-09-16

**源代码**

```python
In [1]: from selenium import webdriver

In [2]: browser = webdriver.Firefox()
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
D:\Anaconda\lib\site-packages\selenium\webdriver\common\service.py in start(self
)
     75                                             stderr=self.log_file,
---> 76                                             stdin=PIPE)
     77         except TypeError:

D:\Anaconda\lib\subprocess.py in __init__(self, args, bufsize, executable, stdin
, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, st
artupinfo, creationflags, restore_signals, start_new_session, pass_fds)
    946                                 errread, errwrite,
--> 947                                 restore_signals, start_new_session)
    948         except:

D:\Anaconda\lib\subprocess.py in _execute_child(self, args, executable, preexec_
fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p
2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_st
art_new_session)
   1223                                          cwd,
-> 1224                                          startupinfo)
   1225             finally:

FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

WebDriverException                        Traceback (most recent call last)
<ipython-input-2-0de604b158b8> in <module>()
----> 1 browser = webdriver.Firefox()

D:\Anaconda\lib\site-packages\selenium\webdriver\firefox\webdriver.py in __init_
_(self, firefox_profile, firefox_binary, timeout, capabilities, proxy, executabl
e_path, options, service_log_path, firefox_options, service_args, desired_capabi
lities, log_path)
    155                 service_args=service_args,
    156                 log_path=service_log_path)
--> 157             self.service.start()
    158
    159             capabilities.update(options.to_capabilities())

D:\Anaconda\lib\site-packages\selenium\webdriver\common\service.py in start(self
)
     81                 raise WebDriverException(
     82                     "'%s' executable needs to be in PATH. %s" % (
---> 83                         os.path.basename(self.path), self.start_error_me
ssage)
     84                 )
     85             elif err.errno == errno.EACCES:

WebDriverException: Message: 'geckodriver' executable needs to be in PATH.

In [11]: browser = webdriver.Firefox(executable_path='D:\geckodriver\geckodriver')
In [12]: type(browser)
Out[12]: selenium.webdriver.firefox.webdriver.WebDriver
In [14]:  browser.get('http://inventwithpython.com')

from selenium import webdriver
browser = webdriver.Firefox(executable_path='D:\geckodriver\geckodriver')
browser.get('http://inventwithpython.com')
try:
    elem = browser.find_element_by_class_name('bookcover')
    print('Found <%s> element with that class name!' % (elem.tag_name))
except:
    print('Was not able to find an element with that name.')

    Was not able to find an element with that name.

In [15]: from selenium import webdriver
In [16]: browser = webdriver.FireFox(executable_path='D:\geckodriver\geckodriver')
    ...:
    ...:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-16-b933ec9bfd08> in <module>()
----> 1 browser = webdriver.FireFox(executable_path='D:\geckodriver\geckodriver')
      2

AttributeError: module 'selenium.webdriver' has no attribute 'FireFox'

In [17]: browser = webdriver.Firefox(executable_path='D:\geckodriver\geckodriver')
In [18]: browser.get('http://inventwithpython.com')
In [20]: linkElem = browser.find_element_by_link_text('More Info')
In [21]: type(linkElem)
Out[21]: selenium.webdriver.firefox.webelement.FirefoxWebElement
In [22]: linkElem.click()

    from selenium import webdrivor
In [25]: = webdriver.Firefox()
In [26]:browser.get('http://gmail.com')
In [27]:emailElem= browser.find_element_by_id('Email')
In [28]:browser.send_keys('not_my_real_email@gmail.com')
In [29]:passwordElem= browser.find_element_by_id('Passwd')
In [30]:passwordElem.send_keys('12345')
In [31]:passwordElem.submit()
In [32]: from selenium import webdriver

In [33]: from selenium.webdriver.common.keys import Keys

In [34]:  browser = webdriver.Firefox(executable_path='D:\geckodriver\geckodriver')
    ...:

In [35]: browser.get('http://nostarch.com')

In [36]: htmlElem = browser.find_element_by_tag_name('html')

In [37]: htmlElem.send_keys(Keys.END) # scrolls to bottom

In [38]: htmlElem.send_keys(Keys.HOME) # scrolls to top


    Practice question
1.webbrowser 模块,启动web 浏览器，打开指定的URL。
Requests 模块可以从网上下载文件和页面。
BeautifulSoup 模块解析HTML
selenium 模块可以启动并控制浏览器。
2.requests.get() 返回一个Response 对象 它有一个text 属性，包含下载内容的字符串。
3．如果下载有问题，raise_for_status() 方法将抛出异常
4.Response 对象的status_code 属性包含了HTTP 状态码。
5.以'wb'，即“写二进制”模式在你的计算机上打开新文件后，利用一个 for
循环迭代遍历Response 对象的iter_content() 方法，将各段写入该文件
7.右键点击页面上的元素，并从菜单中选择Inspect Element。
8．'#main'
9.'.highlight'
10．'div div'
11．'button[value="favorite"]'
12．spam.getText()
13．linkElem.attrs
14．selenium 模块是通过from selenium import webdriver 导入的。
15．find_element_* 方法将第一个匹配的元素返回，作为一个 WebElement 对象。
find_elements_* 方法返回所有匹配的元素，作为一个WebElement 对象列表。
16．click() 和send_keys() 方法分别模拟鼠标点击和键盘按键。
17．对表单中的任意对象调用submit() 方法将提交该表单。
18．forward()、back() 和refresh() 等WebDriver 对象方法模拟了这些浏览器按钮。
```

**错题集**

```python
In [2]: browser = webdriver.Firefox()
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
D:\Anaconda\lib\site-packages\selenium\webdriver\common\service.py in start(self
)
     75                                             stderr=self.log_file,
---> 76                                             stdin=PIPE)
     77         except TypeError:

D:\Anaconda\lib\subprocess.py in __init__(self, args, bufsize, executable, stdin
, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, st
artupinfo, creationflags, restore_signals, start_new_session, pass_fds)
    946                                 errread, errwrite,
--> 947                                 restore_signals, start_new_session)
    948         except:

D:\Anaconda\lib\subprocess.py in _execute_child(self, args, executable, preexec_
fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p
2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_st
art_new_session)
   1223                                          cwd,
-> 1224                                          startupinfo)
   1225             finally:

FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

WebDriverException                        Traceback (most recent call last)
<ipython-input-2-0de604b158b8> in <module>()
----> 1 browser = webdriver.Firefox()

D:\Anaconda\lib\site-packages\selenium\webdriver\firefox\webdriver.py in __init_
_(self, firefox_profile, firefox_binary, timeout, capabilities, proxy, executabl
e_path, options, service_log_path, firefox_options, service_args, desired_capabi
lities, log_path)
    155                 service_args=service_args,
    156                 log_path=service_log_path)
--> 157             self.service.start()
    158
    159             capabilities.update(options.to_capabilities())

D:\Anaconda\lib\site-packages\selenium\webdriver\common\service.py in start(self
)
     81                 raise WebDriverException(
     82                     "'%s' executable needs to be in PATH. %s" % (
---> 83                         os.path.basename(self.path), self.start_error_me
ssage)
     84                 )
     85             elif err.errno == errno.EACCES:

WebDriverException: Message: 'geckodriver' executable needs to be in PATH
 应对方法
1.安装Firefox geckodriver
  地址https://github.com/mozilla/geckodriver/releases
  解压缩：该软件无需安装，解压缩即可
2.用browser = webdriver.Firefox(executable_path='D:\geckodriver\geckodriver')替换
  browser = webdriver.Firefox()

```

**今日所学**

controlling the browser with the selenium module

finding elements on the page

clicking the page

filling out and submitting forms

sending special keys

practice qiestions

